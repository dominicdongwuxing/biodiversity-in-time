
'''
Get the tree dataframe generated by pbdb data. It has the following attributes:

pathFromRoot: a comma separated string that notes the path from Eukaryota root to its name
note that this is also the unique id for this node/leaf.

name: the part of pathFromRoot after last comma

parent: the pathFromRoot of its parent, which is the string before the last comma in pathFromRoot

wikiRef: a reference Q_code from wiki data, if available, this is when there is a match between 
the two datasets, regarding both name and rank 

count: the aggregated count for this taxon, namely, the fossil belonging to itself and its substree

maxma: the max of the maxma for fossils belonging to itself and its subtree

minma: the min of minma for fossils belonging to itself and its subtree
'''

import pandas as pd
import numpy as np
import string
import os
import re
import json
import collections

# ROOTDIR is where I have my thesis folder on my computer
ROOTDIR = "/home/dongwuxing/Documents/thesis"
DATADIR = ROOTDIR + "/dataset"
PBDBDIR = DATADIR + "/pbdb"
WIKIDIR = DATADIR + "/wikidata/processed"

def get_additional_nodes(tree):
    '''
    Helps to add nodes to the tree dataframe. It iterates through all
    possible paths and add all nodes along those paths that are
    not present in the tree dataframe.
    
    input: immature tree dataframe
    return: new dataframe with the missing nodes to append to tree dataframe
    '''
    ranks = ["domain","kingdom","phylum","class","order","family","genus"]
    # extract all current nodes/leaves from all paths
    current_nodes = set(tree["pathFromRoot"].unique().tolist())
    # initialize lists to be added
    pathFromRoot_list = []
    name_list = []
    rank_list = []
    # check for each path if unseen nodes need to be added
    for path in current_nodes:
        # find all indices of comma
        indices = [i.start() for i in re.finditer(",",path)]
        for i in indices:
            node = path[:i]
            # add each node along the path if the node is not there
            if node not in current_nodes:
                pathFromRoot_list.append(node)
                name_list.append(node.split(",")[-1])
                # find out which rank name it has by counting its last comma position
                rank_list.append(ranks[len(node.split(","))-1])
    
    pd_to_add = pd.DataFrame(data={"pathFromRoot":pathFromRoot_list, "name": name_list, "rank":rank_list}).drop_duplicates()
    return pd_to_add

def append_unique_name(tree, repetitive_names):
    '''
    Append a unique name attribute, where if the name is already unique, is just
    the name, but if the name is not unique, then it is its pathFromRoot
    input: tree data frame, a set of repetitive names
    output: tree appended with unique name attribute
    '''
    unique_name_list = [""]*tree.shape[0]
    for i, row in tree.iterrows():
        if row["name"] in repetitive_names:
            unique_name_list[i] = row["pathFromRoot"]
        else:
            unique_name_list[i] = row["name"]
    tree["uniqueName"] = unique_name_list
    return tree

def append_parent (tree):
    '''
    Add parent attribute for each tree item by uniqueName
    
    input: tree dataframe
    return: tree appended with parent attribute
    '''
    tree["parent"] = [""]*tree.shape[0]
    # set pathFromRoot as index for tree for faser processing
    tree = tree.set_index("pathFromRoot")
    index = 0
    for pathFromRoot in tree.index.values:
        index += 1
        if index % 5000 == 0:
            print(index)
        last_comma_index = pathFromRoot.rfind(",")
        # if the node is not the root Eukaryota
        if last_comma_index != -1 :
            parentPathFromRoot = pathFromRoot[:last_comma_index]
            tree.loc[pathFromRoot,"parent"] = tree.loc[parentPathFromRoot,"uniqueName"]
    
    
    tree.reset_index(inplace=True)
    
    return tree

def get_name_id_dict (wiki):
    '''
    input: the wiki dataset in pandas dataframe
    return: a dict, where keys are taxon names, values are lists of corresponding id (Q code) 
    '''
    name_id_dict = {}
    for idx in wiki.index:
        name = wiki.loc[idx,"taxon_name"]
        if name not in name_id_dict:
            name_id_dict[name] = [idx]
        else:
            name_id_dict[name].append(idx)
    return name_id_dict

def get_wikiRef(tree, wikidata, name_id_lookup, repetitive_names):
    '''
    Find wikiRef links for tree elements from wikidata. The wikiRef is a unique code starting with Q
    and there is a match if only there is an exact match beween name and rank and the match has to be unique
    
    input: tree dataframe, wiki dataframe, name_id_lookup for wiki dataframe, and set of repetitive names
    return: a list of wikiRef for tree dataframe to append to tree dataframe
    '''
    wikiRef_list = [""] * tree.shape[0]
    for i, row in tree.iterrows():
        if i % 5000 == 0:
            print(i)
        name, rank = row["name"], row["rank"]
        if name in name_id_lookup and name not in repetitive_names:
            # get Q_codes (there maybe multiple) that links to the same taxon name
            codes = name_id_lookup[name]
            # only proceed when there is only one match
            if len(codes) == 1:
                # check if the rank information is also correct 
                if rank == wikidata.loc[codes[0]].taxon_rank:
                    wikiRef_list[i] = codes[0]
    return wikiRef_list

def append_count_and_time (tree, data):
    '''
    For each node, aggregate the count and maxma and minma information.
    count: the total number of fossils mapped to this node and below;
    maxma: max of maxma of all the fossils mapped to this node and below;
    minma: same as maxma but for minma
    
    input: tree and fossil dataframes
    return: tree data appended with count maxma and minma attributes
    '''
    # aggregate fossil data by its pathFromRoot, get max of maxma, min of minma and count
    max_df = data[["pathFromRoot","max_ma"]].groupby(["pathFromRoot"]).max()
    min_df = data[["pathFromRoot","min_ma"]].groupby(["pathFromRoot"]).min()
    count_df = data[["pathFromRoot","occurrence_no"]].groupby(["pathFromRoot"]).count()
    
    tree["count"], tree["maxma"], tree["minma"] = [0]*tree.shape[0],[-1]*tree.shape[0],[-1]*tree.shape[0]
    # set pathFromRoot as index for tree for faser processing
    tree = tree.set_index("pathFromRoot")
    
    a = 0
    # for each node/leaf in data
    for node in data["pathFromRoot"].unique().tolist():
        a += 1
        if a % 100 == 0:
            print(a)
        # extract all of its upper stream nodes
        nodes = [node]
        indices = [idx.start() for idx in re.finditer(",",node)]
        for index in indices:
            nodes.append(node[:index])
        count, maxma, minma = count_df.loc[node].occurrence_no, max_df.loc[node].max_ma, min_df.loc[node].min_ma
        for i in nodes:
            tree.loc[i,"count"] += count
            current_maxma, current_minma = float(tree.loc[i, "maxma"]), float(tree.loc[i, "minma"])
            if current_maxma < maxma:
                tree.loc[i, "maxma"] = maxma
            if current_minma == -1 or current_minma > minma:
                tree.loc[i, "minma"] = minma
    tree.reset_index(inplace=True)
    return tree

def append_children(tree):
    '''
    Add children attribute, which is a list of uniqueNames
    input: tree dataframe
    return: tree appended with children
    '''
    children_list = [[]]*tree.shape[0]
    for i, row in tree.iterrows():
        if i % 100 == 0:
            print(i)
        children_list[i] = tree[tree["parent"]==row["uniqueName"]].uniqueName.tolist()
    tree["children"] = children_list
    return tree

def append_fossil_identified_to_name(tree, data):
    '''
    Append for each node, the number of fossils identified to this node
    input: tree and fossil dataframes
    return: tree data appended with fossil_identified_to_name
    '''
    count_df = data[["pathFromRoot","occurrence_no"]].groupby(["pathFromRoot"]).count()
    tree["fossilCountIdentifiedToName"] = [0] * tree.shape[0]
    tree = tree.set_index("pathFromRoot")
    for pathFromRoot in count_df.index.values:
        tree.loc[pathFromRoot, "fossilCountIdentifiedToName"] = count_df.loc[pathFromRoot].occurrence_no
    tree.reset_index(inplace=True)
    return tree
#####################################################################################################################

data = pd.read_csv(os.path.join(PBDBDIR, "data.csv"))
# init tree dataframe
tree = data[["pathFromRoot","name","rank"]].drop_duplicates()
tree = tree.reset_index(drop=True)
# add the missing nodes along the paths to the tree
pd_to_add = get_additional_nodes(tree)
tree = pd.concat([pd_to_add, tree], ignore_index = True)

# get names that appeared for more than once
repetitive_names = set([item for item, count in collections.Counter(tree["name"].tolist()).items() if count > 1])

tree = append_unique_name(tree,repetitive_names)

# add parent attribute to the tree
tree = append_parent(tree)

wikidata = pd.read_csv(os.path.join(WIKIDIR,"data.csv"), index_col = "id")
# match pbdb name to wiki Q_code: first match accepted_name, then genus, family, order, class, phylum and kingdom 
name_id_lookup = get_name_id_dict(wikidata)
wikiRef_list = get_wikiRef(tree, wikidata, name_id_lookup, repetitive_names)
tree["wikiRef"] = wikiRef_list

# add maxma, minma and count information for the tree
tree = append_count_and_time(tree, data)

tree = append_fossil_identified_to_name(tree, data)

tree = append_children(tree)
tree.to_csv(os.path.join(PBDBDIR, "tree.csv"), index = False)
with open(os.path.join(PBDBDIR, "tree.json"),"w") as f:
    json.dump(json.loads(tree.to_json(orient="records")),f)


data["uniqueName"] = data["name"]
for repetitive_name in repetitive_names:
   data.loc[data["name"]==repetitive_name,"uniqueName"] = data.loc[data["name"]==repetitive_name,"pathFromRoot"]