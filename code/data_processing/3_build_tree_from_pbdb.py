
'''
Get the tree dataframe generated by pbdb data. It has the following attributes:

pathFromRoot: a comma separated string that notes the path from Eukaryota root to its name
note that this is also the unique id for this node/leaf.

name: the part of pathFromRoot after last comma

parent: the pathFromRoot of its parent, which is the string before the last comma in pathFromRoot

wikiRef: a reference Q_code from wiki data, if available, this is when there is a match between 
the two datasets, regarding both name and rank 

count: the aggregated count for this taxon, namely, the fossil belonging to itself and its substree

maxma: the max of the maxma for fossils belonging to itself and its subtree

minma: the min of minma for fossils belonging to itself and its subtree
'''

import pandas as pd
import numpy as np
import string
import os
import re
import json

# ROOTDIR is where I have my thesis folder on my computer
ROOTDIR = "/home/dongwuxing/Documents/thesis"
DATADIR = ROOTDIR + "/dataset"
PBDBDIR = DATADIR + "/pbdb"
WIKIDIR = DATADIR + "/wikidata/processed"

def get_additional_nodes(tree):
    '''
    Helps to add nodes to the tree dataframe. It iterates through all
    possible paths and add all nodes along those paths that are
    not present in the tree dataframe.
    
    input: immature tree dataframe
    return: new dataframe with the missing nodes to append to tree dataframe
    '''
    ranks = ["domain","kingdom","phylum","class","order","family","genus"]
    # extract all current nodes/leaves from all paths
    current_nodes = set(tree["pathFromRoot"].unique().tolist())
    # initialize lists to be added
    pathFromRoot_list = []
    name_list = []
    rank_list = []
    # check for each path if unseen nodes need to be added
    for path in current_nodes:
        # find all indices of comma
        indices = [i.start() for i in re.finditer(",",path)]
        for i in indices:
            node = path[:i]
            # add each node along the path if the node is not there
            if node not in current_nodes:
                pathFromRoot_list.append(node)
                name_list.append(node.split(",")[-1])
                # find out which rank name it has by counting its last comma position
                rank_list.append(ranks[len(node.split(","))-1])
    
    pd_to_add = pd.DataFrame(data={"pathFromRoot":pathFromRoot_list, "name": name_list, "rank":rank_list}).drop_duplicates()
    return pd_to_add

def append_parent (tree):
    '''
    Add parent attribute for each tree item, which is the string before last comma
    
    input: tree dataframe
    return: tree appended with parent attribute
    '''
    parent_list = [""]*tree.shape[0]
    for i, row in tree.iterrows():
        last_comma_index = row["pathFromRoot"].rfind(",")
        # if the node is not the root Eukaryota
        if last_comma_index != -1 :
            parent_list[i] = row["pathFromRoot"][:last_comma_index]
    tree["parent"] = parent_list
    return tree

def get_name_id_dict (wiki):
    '''
    input: the wiki dataset in pandas dataframe
    return: a dict, where keys are taxon names, values are lists of corresponding id (Q code) 
    '''
    name_id_dict = {}
    for idx in wiki.index:
        name = wiki.loc[idx,"taxon_name"]
        if name not in name_id_dict:
            name_id_dict[name] = [idx]
        else:
            name_id_dict[name].append(idx)
    return name_id_dict

def get_wikiRef(tree, wikidata, name_id_lookup):
    '''
    Find wikiRef links for tree elements from wikidata. The wikiRef is a unique code starting with Q
    and there is a match if only there is an exact match beween name and rank and the match has to be unique
    
    input: tree dataframe, wiki dataframe, name_id_lookup for wiki dataframe
    return: a list of wikiRef for tree dataframe to append to tree dataframe
    '''
    wikiRef_list = [""] * tree.shape[0]
    for i, row in tree.iterrows():
        name, rank = row["name"], row["rank"]
        if name in name_id_lookup:
            # get Q_codes (there maybe multiple) that links to the same taxon name
            codes = name_id_lookup[name]
            # only proceed when there is only one match
            if len(codes) == 1:
                # check if the rank information is also correct 
                if rank == wikidata.loc[codes[0]].taxon_rank:
                    wikiRef_list[i] = codes[0]
    return wikiRef_list

def append_count_and_time (tree, data):
    '''
    For each node, aggregate the count and maxma and minma information.
    count: the total number of fossils mapped to this node and below;
    maxma: max of maxma of all the fossils mapped to this node and below;
    minma: same as maxma but for minma
    
    input: tree and fossil dataframes
    return: tree data appended with count maxma and minma attributes
    '''
    # aggregate fossil data by its pathFromRoot, get max of maxma, min of minma and count
    max_df = data[["pathFromRoot","max_ma"]].groupby(["pathFromRoot"]).max()
    min_df = data[["pathFromRoot","min_ma"]].groupby(["pathFromRoot"]).min()
    count_df = data[["pathFromRoot","occurrence_no"]].groupby(["pathFromRoot"]).count()
    
    tree["count"], tree["maxma"], tree["minma"] = [0]*tree.shape[0],[-1]*tree.shape[0],[-1]*tree.shape[0]
    # set pathFromRoot as index for tree for faser processing
    tree = tree.set_index("pathFromRoot")
    
    a = 0
    # for each node/leaf in data
    for node in data["pathFromRoot"].unique().tolist():
        a += 1
        if a % 100 == 0:
            print(a)
        # extract all of its upper stream nodes
        nodes = [node]
        indices = [idx.start() for idx in re.finditer(",",node)]
        for index in indices:
            nodes.append(node[:index])
        count, maxma, minma = count_df.loc[node].occurrence_no, max_df.loc[node].max_ma, min_df.loc[node].min_ma
        for i in nodes:
            tree.loc[i,"count"] += count
            current_maxma, current_minma = float(tree.loc[i, "maxma"]), float(tree.loc[i, "minma"])
            if current_maxma < maxma:
                tree.loc[i, "maxma"] = maxma
            if current_minma == -1 or current_minma > minma:
                tree.loc[i, "minma"] = minma
    tree.reset_index(inplace=True)
    return tree

#####################################################################################################################

data = pd.read_csv(os.path.join(PBDBDIR, "data.csv"))
# init tree dataframe
tree = data[["pathFromRoot","name","rank"]].drop_duplicates()
tree = tree.reset_index(drop=True)
# add the missing nodes along the paths to the tree
pd_to_add = get_additional_nodes(tree)
tree = pd.concat([pd_to_add, tree], ignore_index = True)
# add parent attribute to the tree
tree = append_parent(tree)

wikidata = pd.read_csv(os.path.join(WIKIDIR,"data.csv"), index_col = "id")
# match pbdb name to wiki Q_code: first match accepted_name, then genus, family, order, class, phylum and kingdom 
name_id_lookup = get_name_id_dict(wikidata)
wikiRef_list = get_wikiRef(tree, wikidata, name_id_lookup)
tree["wikiRef"] = wikiRef_list

# add maxma, minma and count information for the tree
tree = append_count_and_time(tree, data)

tree.to_csv(os.path.join(PBDBDIR, "tree.csv"), index = False)
with open(os.path.join(PBDBDIR, "tree.json"),"w") as f:
    json.dump(json.loads(tree.to_json(orient="records")),f)

